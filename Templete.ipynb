{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/Acec4L18nCO6MYByPDfV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYjgVBsvFdvl",
        "outputId": "8823fb1b-ca0f-42d4-fa6c-6ecc44a59233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.10.0 typing-extensions-4.9.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.85 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#완성형 언어 모델의 프롬프트\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "string_prompt = PromptTemplate.from_template('Tell me a joke about {subject}')\n",
        "string_prompt_value = string_prompt.format_prompt(subject = 'soccer')\n",
        "\n",
        "string_prompt_value.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FHjxW05rNIfn",
        "outputId": "6619d7c7-e072-4639-9b18-be39259af046"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#대화형 언어 모델의 프롬프트\n",
        "chat_prompt = ChatPromptTemplate.from_template('Tell me a joke about {subject}')\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject = 'soccer')\n",
        "\n",
        "chat_prompt_value.messages[0].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ayT8pxH9N6To",
        "outputId": "8086b0b6-eac0-430a-c90c-a86f855d6b3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''\n",
        " 너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라.\n",
        " 내가 가진 재료는 아래와 같다.\n",
        " <재료>\n",
        " {재료}\n",
        "'''"
      ],
      "metadata": {
        "id": "fb3Bj4fUO3IN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "                     input_variables=['재료'],\n",
        "                     template = template\n",
        ")\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycYxIPZtPZsM",
        "outputId": "3c1ab16e-34f5-4c61-e0ac-8e632ab6175e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['재료'], template='\\n 너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라.\\n 내가 가진 재료는 아래와 같다.\\n <재료>\\n {재료}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.format(재료 = '양파, 계란, 사과 , 빵')"
      ],
      "metadata": {
        "id": "jiDH_SgdQBfF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '8c91c5c7058847f3820f9d7c12bbb1fb'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://sktfly-ai.openai.azure.com/'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'"
      ],
      "metadata": {
        "id": "3A6258wjQcCo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "EAzEj8vMQjw7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(\n",
        "    deployment_name = 'dev-gpt-35-turbo-instruct',\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "jWj0x2buQ8lK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "mzh5Wa2oRjoi",
        "outputId": "aebf90b1-c0e2-4a90-a471-e61d2750c7e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n너는 사과 계란 후라이를 추천할 수 있을 것 같아. 그 요리의 레시피는 아래와 같아!\\n\\n사과 계란 후라이 레시피:\\n1. 양파를 썰어서 먼저 기름에 볶아준다.\\n2. 그 다음 계란을 넣어서 익힌다.\\n3. 사과를 썰어서 양파와 계란 위에 올려준다.\\n4. 빵을 토스트 해서 사과 계란 후라이랑 함께 즐긴다! 맛있는 아침식사가 완성되었다!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import(\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "from langchain.schema import(\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "JxKqSVokSetJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#탬플릿 완성\n",
        "\n",
        "# system template\n",
        "system_template_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "#human template\n",
        "human_template = '{재료}'\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "#chat template\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_template_prompt,\n",
        "                                               human_message_prompt])\n",
        "\n",
        "prompt = chat_prompt.format_prompt(재료 = '양파, 계란, 사과, 빵').to_messages()\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElezRgoaTDrm",
        "outputId": "4761ddd2-6b21-4592-b002-e27b848eb4a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='\\n 너는 요리사다. 내가 가진 재료들을 가지고 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해라.\\n 내가 가진 재료는 아래와 같다.\\n <재료>\\n 양파, 계란, 사과, 빵\\n'),\n",
              " HumanMessage(content='양파, 계란, 사과, 빵')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = AzureChatOpenAI(deployment_name = 'dev-gpt-35-turbo')\n",
        "answer = chatgpt(prompt)\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzLvpEkXYKmK",
        "outputId": "80f4e9ce-6d73-42da-f11b-a136547b7bc1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가지고 계신 재료들로는 \"양파 계란 토스트\"를 만들 수 있습니다. \n",
            "\n",
            "레시피는 아래와 같습니다.\n",
            "\n",
            "재료:\n",
            "- 양파\n",
            "- 계란\n",
            "- 빵\n",
            "- 소금\n",
            "- 후추\n",
            "- 식용유\n",
            "\n",
            "조리법:\n",
            "1. 양파를 얇게 썰어 준비합니다.\n",
            "2. 팬에 식용유를 두르고 양파를 볶아 투명해질 때까지 볶습니다.\n",
            "3. 볶은 양파를 삶은 계란과 함께 잘 섞어 소금과 후추로 간을 합니다.\n",
            "4. 빵을 토스트기에 구워 준비합니다.\n",
            "5. 토스트된 빵 위에 양파와 계란을 올려 완성합니다.\n",
            "\n",
            "이렇게하면 맛있는 \"양파 계란 토스트\"를 즐길 수 있습니다. 맛있게 드세요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#few-show learning template\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "examples = [\n",
        "    {\n",
        "        'question' : '아이유로 삼행시를 지어줘.',\n",
        "        'answer' : '''\n",
        "        아 아이유는\n",
        "        이 이상하고\n",
        "        유 유난히 좋다.\n",
        "        '''\n",
        "\n",
        "    },\n",
        "    {\n",
        "        'question' : '이순신으로 삼행시를 지어줘.',\n",
        "        'answer' : '''\n",
        "        이 이순신 장군은\n",
        "        순 순순히 내어줄 것 같았던 조선의 바다를\n",
        "        신 신의와 충의의 마음으로 지켰다.\n",
        "        '''\n",
        "\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Nnswsc_AZ1-A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=['question', 'answer'],\n",
        "                                template = 'Question : {question}\\n{answer}')\n",
        "\n",
        "print(example_prompt.format(** examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PV4OfBubOSd",
        "outputId": "3c01b45a-b837-42d7-8eac-8f233158b96d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question : 아이유로 삼행시를 지어줘.\n",
            "\n",
            "        아 아이유는\n",
            "        이 이상하고\n",
            "        유 유난히 좋다.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples = examples,\n",
        "    example_prompt= example_prompt,\n",
        "    suffix = 'Question: {input}',\n",
        "    input_variables = ['input']\n",
        ")"
      ],
      "metadata": {
        "id": "zUMOJPlEbOQd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# template 사용 안함\n",
        "llm.invoke('호날두로 삼행시를 지어줘.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xyYdCnPFbON8",
        "outputId": "ea90f108-490e-46d0-924c-02cce77aae48"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n너의 손으로 빅맥을 먹어\\n축구의 신이여, 그리고 음식의 왕\\n무엇이든 너의 손에 닿으면 다 바뀌어 버려'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# template 사용\n",
        "llm(prompt.format(input = '호날두로 삼행시를 지어줘.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gRu7LLccdvqT",
        "outputId": "d49b384a-1383-48f7-c4e6-d8d568b4fc08"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n        호 호날두는\\n        날 날렵한 발로\\n        두 두려움을 무찌르는 축구의 신이다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke('뉴진스로 삼행시를 지어줘.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5zS4veXPeins",
        "outputId": "6ff2e1d0-273b-495c-8074-176e11522f88"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n이젠 시작해볼까요\\n마음 속에 담은 삼행시\\n고장난 전구, 눈 내리는 밤\\n눈을 감으면 그리운 얼굴이 보여요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}