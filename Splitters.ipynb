{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcxparCpSYDbOeONQdST3F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yRyUzXprMAui"
      },
      "outputs": [],
      "source": [
        "# Text file을 열어서 내용을 가져온다.\n",
        "with open('/content/generative ai.txt') as f:\n",
        "  text_gen_ai = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vDwNgH_MlQV",
        "outputId": "56193928-2dbc-4589-ae3e-b207c382434f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain)\n",
            "  Downloading langchain_community-0.0.17-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.18-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pypdf, mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.17 langchain-core-0.1.18 langsmith-0.0.85 marshmallow-3.20.2 mypy-extensions-1.0.0 pypdf-4.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n\\n',\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 100,\n",
        "    length_function = len\n",
        ")"
      ],
      "metadata": {
        "id": "CITxmUymNoN_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_text(text_gen_ai)\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KeoLAhINoGQ",
        "outputId": "ea542e44-201d-45fb-e2ed-05909ae5b90a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1003, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2239, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5023, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3461, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1266, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1143, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2523, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "print('-' * 100)\n",
        "print(texts[1])\n",
        "print('-' * 100)\n",
        "print(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KkmvLPVNoC0",
        "outputId": "4ce78cf3-02ae-4937-e227-91e9a857971c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is generative AI?\n",
            "Generative AI can learn from existing artifacts to generate new, realistic artifacts (at scale) that reflect the characteristics of the training data but don’t repeat it. It can produce a variety of novel content, such as images, video, music, speech, text, software code and product designs.  \n",
            "Generative AI uses a number of techniques that continue to evolve. Foremost are AI foundation models, which are trained on a broad set of unlabeled data that can be used for different tasks, with additional fine-tuning. Complex math and enormous computing power are required to create these trained models, but they are, in essence, prediction algorithms. \n",
            "Today, generative AI most commonly creates content in response to natural language requests — it doesn’t require knowledge of or entering code — but the enterprise use cases are numerous and include innovations in drug and chip design and material science development. (Also see “What are some practical uses of generative AI?”)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "What’s behind the sudden hype about generative AI?\n",
            "Gartner has tracked generative AI on its Hype Cycle™ for Artificial Intelligence since 2020 (also, generative AI was among our Top Strategic Technology Trends for 2022), and the technology has moved from the Innovation Trigger phase to the Peak of Inflated Expectations. But generative AI only hit mainstream headlines in late 2022 with the launch of ChatGPT, a chatbot capable of very human-seeming interactions.\n",
            "ChatGPT, launched by OpenAI, became wildly popular overnight and galvanized public attention. (OpenAI’s DALL·E 2 tool similarly generates images from text in a related generative AI innovation.)\n",
            "Gartner sees generative AI becoming a general-purpose technology with an impact similar to that of the steam engine, electricity and the internet. The hype will subside as the reality of implementation sets in, but the impact of generative AI will grow as people and enterprises discover more innovative applications for the technology in daily work and life.\n",
            "FAQ on ChatGPT \n",
            "What are the benefits and applications of generative AI?\n",
            "Foundation models, including generative pretrained transformers (which drives ChatGPT), are among the AI architecture innovations that can be used to automate, augment humans or machines, and autonomously execute business and IT processes. \n",
            "The benefits of generative AI include faster product development, enhanced customer experience and improved employee productivity, but the specifics depend on the use case. End users should be realistic about the value they are looking to achieve, especially when using a service as is, which has major limitations. Generative AI creates artifacts that can be inaccurate or biased, making human validation essential and potentially limiting the time it saves workers. Gartner recommends connecting use cases to KPIs to ensure that any project either improves operational efficiency or creates net new revenue or better experiences.\n",
            "In a recent Gartner webinar poll of more than 2,500 executives, 38% indicated that customer experience and retention is the primary purpose of their generative AI investments. This was followed by revenue growth (26%), cost optimization (17%) and business continuity (7%).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "What are the risks of generative AI?\n",
            "The risks associated with generative AI are significant and rapidly evolving. A wide array of threat actors have already used the technology to create “deep fakes” or copies of products, and generate artifacts to support increasingly complex scams.\n",
            "ChatGPT and other tools like it are trained on large amounts of publicly available data. They are not designed to be compliant with General Data Protection Regulation (GDPR) and other copyright laws, so it’s imperative to pay close attention to your enterprises’ uses of the platforms. \n",
            "Oversight risks to monitor include:\n",
            "\t•\tLack of transparency. Generative AI and ChatGPT models are unpredictable, and not even the companies behind them always understand everything about how they work.\n",
            "\t•\tAccuracy. Generative AI systems sometimes produce inaccurate and fabricated answers. Assess all outputs for accuracy, appropriateness and actual usefulness before relying on or publicly distributing information. \n",
            "\t•\tBias. You need policies or controls in place to detect biased outputs and deal with them in a manner consistent with company policy and any relevant legal requirements.\n",
            "\t•\tIntellectual property (IP) and copyright. There are currently no verifiable data governance and protection assurances regarding confidential enterprise information. Users should assume that any data or queries they enter into the ChatGPT and its competitors will become public information, and we advise enterprises to put in place controls to avoid inadvertently exposing IP. \n",
            "\t•\tCybersecurity and fraud. Enterprises must prepare for malicious actors’ use of generative AI systems for cyber and fraud attacks, such as those that use deep fakes for social engineering of personnel, and ensure mitigating controls are put in place. Confer with your cyber-insurance provider to verify the degree to which your existing policy covers AI-related breaches.\n",
            "\t•\tSustainability. Generative AI uses significant amounts of electricity. Choose vendors that reduce power consumption and leverage high-quality renewable energy to mitigate the impact on your sustainability goals.\n",
            "Gartner also recommends considering the following questions:\n",
            "\t•\tWho defines responsible use of generative AI, especially as cultural norms evolve and social engineering approaches vary across geographies? Who ensures compliance? What are the consequences for irresponsible use? \n",
            "\t•\tIn the event something goes wrong, how can individuals take action?\n",
            "\t•\tHow do users give and remove consent (opt in or opt out)? What can be learned from the privacy debate?\n",
            "\t•\tWill using generative AI help or hurt trust in your organization — and institutions overall?\n",
            "\t•\tHow can we ensure that content creators and owners keep control of their IP and are compensated fairly? What should new economic models look like? \n",
            "\t•\tWho will ensure proper functioning throughout the entire life cycle, and how will they do so? Do boards need an AI ethics lead, for example?\n",
            "Finally, it’s important to continually monitor regulatory developments and litigation regarding generative AI. China and Singapore have already put in place new regulations regarding the use of generative AI, while Italy temporarily. The U.S., Canada, India, the U.K. and the EU are currently shaping their regulatory environments.\n",
            "Also see, “What are the best practices for using generative AI?” and “Should I craft a usage policy for generative AI?”\n",
            "GenAI Risks & Opportunities \n",
            "What are some practical uses of generative AI today?\n",
            "The field of generative AI will progress rapidly in both scientific discovery and technology commercialization, but use cases are emerging quickly in creative content, content improvement, synthetic data, generative engineering and generative design. \n",
            "In-use, high-level practical applications today include the following.\n",
            "\t•\tWritten content augmentation and creation: Producing a “draft” output of text in a desired style and length\n",
            "\t•\tQuestion answering and discovery: Enabling users to locate answers to input, based on data and prompt information\n",
            "\t•\tTone: Text manipulation, to soften language or professionalize text\n",
            "\t•\tSummarization: Offering shortened versions of conversations, articles, emails and webpages\n",
            "\t•\tSimplification: Breaking down titles, creating outlines and extracting key content\n",
            "\t•\tClassification of content for specific use cases: Sorting by sentiment, topic, etc.\n",
            "\t•\tChatbot performance improvement: Bettering “sentity” extraction, whole-conversation sentiment classification and generation of journey flows from general descriptions\n",
            "\t•\tSoftware coding: Code generation, translation, explanation and verification\n",
            "Emerging use cases with long-term impacts include:\n",
            "\t•\tCreating medical images that show the future development of a disease \n",
            "\t•\tSynthetic data helping augment scarce data, mitigate bias, preserve data privacy and simulate future scenarios\n",
            "\t•\tApplications proactively suggesting additional actions to users and providing them with information\n",
            "\t•\tLegacy code modernization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = []\n",
        "for i in range(len(texts)):\n",
        "  char_list.append(texts[i])\n",
        "\n",
        "print(char_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHFxMF9-Nn5S",
        "outputId": "36e76be4-5b68-45b1-fba8-3c1d188d1ec9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What is generative AI?\\nGenerative AI can learn from existing artifacts to generate new, realistic artifacts (at scale) that reflect the characteristics of the training data but don’t repeat it. It can produce a variety of novel content, such as images, video, music, speech, text, software code and product designs.\\xa0\\xa0\\nGenerative AI uses a number of techniques that continue to evolve. Foremost are AI foundation models, which are trained on a broad set of unlabeled data that can be used for different tasks, with additional fine-tuning.\\xa0Complex math and enormous computing power are required to create these trained models, but they are, in essence, prediction algorithms.\\xa0\\nToday, generative AI most commonly creates content in response to natural language requests — it doesn’t require knowledge of or entering code — but the\\xa0enterprise use cases\\xa0are numerous and include innovations in drug and chip design and material science development. (Also see “What are some practical uses of generative AI?”)', 'What’s behind the sudden hype about generative AI?\\nGartner has tracked generative AI on its\\xa0Hype Cycle™ for\\xa0Artificial Intelligence\\xa0since 2020 (also, generative AI was among our Top Strategic Technology Trends for 2022), and the technology has moved from the Innovation Trigger phase to the Peak of Inflated Expectations. But generative AI only hit mainstream headlines in late 2022 with the launch of ChatGPT, a chatbot capable of very human-seeming interactions.\\nChatGPT, launched by OpenAI, became wildly popular overnight and galvanized public attention. (OpenAI’s DALL·E 2 tool similarly generates images from text in a related generative AI innovation.)\\nGartner sees generative AI becoming a general-purpose technology with an impact similar to that of the steam engine, electricity and the internet. The hype will subside as the reality of implementation sets in, but the impact of generative AI will grow as people and enterprises discover more innovative applications for the technology in daily work and life.\\nFAQ on ChatGPT\\xa0\\nWhat are the benefits and applications of generative AI?\\nFoundation models, including generative pretrained transformers (which drives ChatGPT), are among the AI architecture innovations that can be used to automate, augment humans or machines, and autonomously execute business and IT processes.\\xa0\\nThe benefits of generative AI include faster product development, enhanced customer experience and improved employee productivity, but the specifics depend on the use case. End users should be realistic about the value they are looking to achieve, especially when using a service as is, which has major limitations. Generative AI creates artifacts that can be inaccurate or biased, making human validation essential and potentially limiting the time it saves workers. Gartner recommends connecting use cases to KPIs to ensure that any project either improves operational efficiency or creates net new revenue or better experiences.\\nIn a recent Gartner webinar poll of more than 2,500 executives, 38% indicated that customer experience and retention is the primary purpose of their generative AI investments. This was followed by revenue growth (26%), cost optimization (17%) and business continuity (7%).', 'What are the risks of generative AI?\\nThe risks associated with generative AI are significant and rapidly evolving. A wide array of threat actors have already used the technology to create “deep fakes” or copies of products, and generate artifacts to support increasingly complex scams.\\nChatGPT and other tools like it are trained on large amounts of publicly available data. They are not designed to be compliant with General Data Protection Regulation (GDPR) and other copyright laws, so it’s imperative to pay close attention to your enterprises’ uses of the platforms.\\xa0\\nOversight risks to monitor include:\\n\\t•\\tLack of transparency.\\xa0Generative AI and ChatGPT models are unpredictable, and not even the companies behind them always understand everything about how they work.\\n\\t•\\tAccuracy.\\xa0Generative AI systems sometimes produce inaccurate and fabricated answers. Assess all outputs for accuracy, appropriateness and actual usefulness before relying on or publicly distributing information.\\xa0\\n\\t•\\tBias.\\xa0You need policies or controls in place to detect biased outputs and deal with them in a manner consistent with company policy and any relevant legal requirements.\\n\\t•\\tIntellectual property (IP) and copyright.\\xa0There are currently no verifiable data governance and protection assurances regarding confidential enterprise information. Users should assume that any data or queries they enter into the ChatGPT and its competitors will become public information, and we advise enterprises to put in place controls to avoid inadvertently exposing IP.\\xa0\\n\\t•\\tCybersecurity and fraud.\\xa0Enterprises must prepare for malicious actors’ use of generative AI systems for cyber and fraud attacks, such as those that use deep fakes for social engineering of personnel, and ensure mitigating controls are put in place. Confer with your cyber-insurance provider to verify the degree to which your existing policy covers AI-related breaches.\\n\\t•\\tSustainability.\\xa0Generative AI uses significant amounts of electricity. Choose vendors that reduce power consumption and leverage high-quality renewable energy to mitigate the impact on your sustainability goals.\\nGartner also recommends considering the following questions:\\n\\t•\\tWho defines responsible use of generative AI, especially as cultural norms evolve and social engineering approaches vary across geographies? Who ensures compliance? What are the consequences for irresponsible use? \\n\\t•\\tIn the event something goes wrong, how can individuals take action?\\n\\t•\\tHow do users give and remove consent (opt in or opt out)? What can be learned from the privacy debate?\\n\\t•\\tWill using generative AI help or hurt trust in your organization — and institutions overall?\\n\\t•\\tHow can we ensure that content creators and owners keep control of their IP and are compensated fairly? What should new economic models look like?\\xa0\\n\\t•\\tWho will ensure proper functioning throughout the entire life cycle, and how will they do so? Do boards need an AI ethics lead, for example?\\nFinally, it’s important to continually monitor regulatory developments and litigation regarding generative AI. China and Singapore have already put in place new regulations regarding the use of generative AI, while Italy temporarily. The U.S., Canada, India, the U.K. and the EU are currently shaping their regulatory environments.\\nAlso see, “What are the best practices for using generative AI?” and “Should I craft a usage policy for generative AI?”\\nGenAI Risks & Opportunities\\xa0\\nWhat are some practical uses of generative AI today?\\nThe field of generative AI will progress rapidly in both scientific discovery and technology commercialization, but use cases are emerging quickly in creative content, content improvement, synthetic data, generative engineering and generative design.\\xa0\\nIn-use, high-level practical applications today include the following.\\n\\t•\\tWritten content augmentation and creation:\\xa0Producing a “draft” output of text in a desired style and length\\n\\t•\\tQuestion answering and discovery:\\xa0Enabling users to locate answers to input, based on data and prompt information\\n\\t•\\tTone:\\xa0Text manipulation, to soften language or professionalize text\\n\\t•\\tSummarization:\\xa0Offering shortened versions of conversations, articles, emails and webpages\\n\\t•\\tSimplification:\\xa0Breaking down titles, creating outlines and extracting key content\\n\\t•\\tClassification of content for specific use cases:\\xa0Sorting by sentiment, topic, etc.\\n\\t•\\tChatbot performance improvement:\\xa0Bettering “sentity” extraction, whole-conversation sentiment classification and generation of journey flows from general descriptions\\n\\t•\\tSoftware coding:\\xa0Code generation, translation, explanation and verification\\nEmerging use cases with long-term impacts include:\\n\\t•\\tCreating medical images that show the future development of a disease \\n\\t•\\tSynthetic data helping augment scarce data, mitigate bias, preserve data privacy and simulate future scenarios\\n\\t•\\tApplications proactively suggesting additional actions to users and providing them with information\\n\\t•\\tLegacy code modernization', '▶\\nHow will generative AI contribute business value?\\nGenerative AI provides new and disruptive opportunities to increase revenue, reduce costs, improve productivity and better manage risk. In the near future, it will become a competitive advantage and differentiator.\\xa0\\nGartner splits the opportunities into three categories.\\nRevenue opportunities\\nProduct development:\\xa0Generative AI will enable enterprises to create new products more quickly. These may include new drugs, less toxic household cleaners, novel flavors and fragrances, new alloys, and faster and better diagnoses.\\nNew revenue channels:\\xa0Gartner research shows that enterprises with greater levels of AI maturity will gain greater benefits to their revenue.\\nCost and productivity opportunities\\nWorker augmentation:\\xa0Generative AI can augment workers’ ability to draft and edit text, images and other media. It can also summarize, simplify and classify content; generate, translate and verify software code; and improve chatbot performance. At this stage, the technology is highly proficient at creating a wide range of artifacts quickly and at scale.\\nLong-term talent optimization:\\xa0Employees will be distinguished by their ability to conceive, execute and refine ideas, projects, processes, services and relationships in partnership with AI. This symbiotic relationship will accelerate time to proficiency and greatly extend the range and competency of workers across the board.\\nProcess improvement:\\xa0Generative AI can derive real, in-context value from vast stores of content, which until now may have gone largely unexploited. This will change workflows.\\nRisk opportunities\\nRisk mitigation:\\xa0Generative AI’s ability to analyze and provide broader and deeper visibility of data, such as customer transactions and potentially faulty software code, enhances pattern recognition and the ability to identify potential risks to the enterprise more quickly.\\xa0\\nSustainability:\\xa0Generative AI may help enterprises comply with\\xa0sustainability\\xa0regulations, mitigate the risk of stranded assets, and embed sustainability into decision making, product design and processes.\\nImpact of Gen AI\\xa0\\nWhich industries are most impacted by generative AI?\\nGenerative AI will affect the pharmaceutical, manufacturing, media, architecture, interior design, engineering, automotive, aerospace, defense, medical, electronics and energy industries by augmenting core processes with AI models. It will impact marketing, design, corporate communications, and training and software engineering by augmenting the supporting processes that span many organizations. For example:\\n\\t•\\tWe believe that by 2025, more than 30% of new drugs and materials will be systematically discovered using generative AI techniques, up from zero today. Generative AI looks promising for the pharmaceutical industry, given the opportunity to reduce costs and time in drug discovery.\\n\\t•\\tWe predict that by 2025, 30% of outbound marketing messages from large organizations will be synthetically generated, up from less than 2% in 2022. Text generators like GPT-3 can already be used to create marketing copy and personalized advertising.\\n\\t•\\tIn the manufacturing, automotive, aerospace and defense industries, generative design can create designs optimized to meet specific goals and constraints, such as performance, materials and manufacturing methods. This accelerates the design process by producing an array of potential solutions for engineers to explore.', 'What are the best practices for using generative AI?\\nTechnologies that provide\\xa0AI trust and transparency\\xa0will become an important complement to generative AI solutions. Also, executive leaders should follow this guidance for ethical use of LLMs and other generative AI models:\\n\\t•\\tStart inside.\\xa0Before using generative AI to create customer- or other external-facing content, test extensively with internal stakeholders and employee use cases. You don’t want hallucinations to harm your business.\\n\\t•\\tPrize transparency.\\xa0Be forthcoming with people, whether they be staff, customers or citizens, about the fact that they are interacting with a machine by clearly labeling any conversation multiple times throughout.\\n\\t•\\tDo your due diligence.\\xa0Set up processes and guardrails to track biases and other issues of trustworthiness. Do so by validating results and continually testing for the model going off course.\\n\\t•\\tAddress privacy and security concerns.\\xa0Ensure that sensitive data is neither input nor derived. Confirm with the model provider that this data won’t be used for machine learning beyond your organization.\\n\\t•\\tTake it slow.\\xa0Keep functionality in beta for an extended period of time. This helps temper expectations for perfect results.\\nResponsible Use of NLT', '▶\\nShould I craft a usage policy for generative AI?\\nYour workforce is likely already using generative AI, either on an experimental basis or to support their job-related tasks. To avoid “shadow” usage and a false sense of compliance, Gartner recommends crafting a usage policy rather than enacting an outright ban.\\xa0\\nKeep the policy simple — it can be as streamlined as three don’ts and two do’s if using ChatGPT or other off-the-shelf model:\\n\\t•\\tDon’t\\xa0input any personally identifiable information.\\n\\t•\\tDon’t\\xa0input any sensitive information.\\n\\t•\\tDon’t\\xa0input any company IP.\\n\\t•\\tDo\\xa0turn off history if using external tools (like ChatGPT) that enable that choice.\\n\\t•\\tDo\\xa0closely monitor outputs, which are subject to sometimes subtle but meaningful hallucinations, factual errors and biased or inappropriate statements.\\nIf the company is using its own instance of a large language model, the privacy concerns that inform limiting inputs go away. However, the need to keep a close eye on outputs remains.', '▶\\nHow will generative AI impact the future of work?\\nIn business, many people are content creators of some kind. Generative AI will significantly alter their jobs, whether it be by creating text, images, hardware designs, music, video or something else. In response, workers will need to become content editors, which requires a different set of skills than content creation.\\nMeanwhile, the way the workforce interacts with applications will change as applications become conversational, proactive and interactive, requiring a redesigned user experience. In the near term, generative AI models will move beyond responding to natural language queries and begin suggesting things you didn’t ask for. For example, your request for a data-driven bar chart might be answered with alternative graphics the model suspects you could use. In theory at least, this will increase worker productivity, but it also challenges conventional thinking about the need for humans to take the lead on developing strategy.\\nThe net change in the workforce will vary dramatically depending on such factors as industry, location, size and offerings of the enterprise.', 'Where should I start with generative AI?\\nMany enterprises have generative AI pilots for code generation, text generation or visual design underway. To establish a pilot, you can take one of three routes:\\n\\t1\\tOff-the-shelf.\\xa0Use an existing foundational model directly by inputting prompts. You might, for example, ask the model to create a job description for a software engineer or suggest alternative subject lines for marketing emails.\\n\\t2\\tPrompt engineering.\\xa0Program and connect software to and leverage a foundational model. This technique, which is the most common of the three, allows you to use public services while protecting IP and leveraging private data to create more precise, specific and useful responses. Building an HR benefits chatbot that answers employee questions about company-specific policies is an example of prompt engineering.\\n\\t3\\tCustom.\\xa0Building a new foundational model goes beyond the reach of most companies, but it’s possible to tune a model. This involves adding a layer or proprietary data in a way that significantly alters the way the foundational model behaves. While costly, customizing a model offers the highest level of flexibility.\\nCreate an AI Strategy\\xa0\\nWhat do I need to buy to enable generative AI?\\nThe costs for generative AI will range from negligible to many millions depending on the use case, scale and requirements of the company. Small and midsize enterprises may derive significant business value from the free versions of public, openly hosted applications, such as ChatGPT, or by paying low subscription fees. For example, OpenAI is currently $20 per user per month. However, free and low-cost options come with minimal protection of enterprise data and associated output risks.\\nLarger enterprises and those that desire greater analysis or use of their own enterprise data with higher levels of security and IP and privacy protections will need to invest in a range of custom services. This can include building licensed, customizable and proprietary models with data and machine learning platforms, and will require working with vendors and partners. In this instance, costs can be in the millions of dollars.\\nIt’s also worth noting that generative AI capabilities will increasingly be built into the software products you likely use everyday, like Bing, Office 365, Microsoft 365 Copilot and Google Workspace. This is effectively a “free” tier, though vendors will ultimately pass on costs to customers as part of bundled incremental price increases to their products.', 'What does Gartner predict for the future of generative AI use?\\nGenerative AI is primed to make an increasingly strong impact on enterprises over the next five years. Gartner predicts that:\\n\\t•\\tBy 2024, 40% of enterprise applications will have embedded conversational AI, up from less than 5% in 2020.\\n\\t•\\tBy 2025, 30% of enterprises will have implemented an AI-augmented development and testing strategy, up from 5% in 2021.\\n\\t•\\tBy 2026, generative design AI will automate 60% of the design effort for new websites and mobile apps.\\xa0\\n\\t•\\tBy 2026, over 100 million humans will engage robocolleagues to contribute to their work.\\n\\t•\\tBy 2027, nearly 15% of new applications will be automatically generated by AI without a human in the loop. This is not happening at all today.\\nGenAI Changes Innovation & Operations\\xa0\\nWho are the major tech providers in the generative AI market?\\nThe Generative AI marketplace is on fire. Beyond the big platform players, there are many hundreds of specialty providers funded by ample venture capital and a wave of new open-source models and capabilities. Enterprise application providers, such as Salesforce and SAP, are building LLM capabilities into their platforms. Organizations like Microsoft, Google, Amazon Web Services (AWS) and IBM have invested hundreds of millions of dollars and massive compute power to build the foundational models on which services like ChatGPT and others depend.\\xa0\\nGartner considers the current major players to be as follows:\\n\\t•\\tGoogle\\xa0has two large language models, Palm, a multimodal model, and Bard, a pure language model. They are embedding their generative AI technology into their suite of workplace applications, which will immediately get it in the hands of millions of people.\\n\\t•\\tMicrosoft and OpenAI\\xa0are marching in lockstep. Like Google, Microsoft is embedding generative AI technology into its products, but it has the first-mover advantage and buzz of ChatGPT on its side.\\n\\t•\\tAmazon\\xa0has partnered with\\xa0Hugging Face, which has a number of LLMs available on an open-source basis, to build solutions. Amazon also has Bedrock, which provides access to generative AI on the cloud via AWS, and has announced plans for Titan, a set of two AI models that create text and improve searches and personalization.\\n\\t•\\tIBM\\xa0has multiple foundation models and a strong ability to fine-tune both its and third-party models by injecting data and retraining and employing the model.\\nConversational AI Platforms\\xa0\\nIs this the start of artificial general intelligence (AGI)?\\nIt depends whom you ask. AGI, the ability of machines to match or exceed human intelligence and solve problems they never encountered during training, provokes vigorous debate and a mix of awe and dystopia. AI is certainly becoming more capable and is displaying sometimes surprising emergent behaviors that humans did not program.\\nThe likely path is the evolution of machine intelligence that mimics human intelligence but is ultimately aimed at helping humans solve complex problems. This will require governance, new regulation and the participation of a wide swath of society.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader('/content/pdf.pdf')\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "WGXbEti9Rvcr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#총 페이지 수\n",
        "print(len(pages))\n",
        "print(type(pages[0]))\n",
        "print(pages[0].metadata)\n",
        "print(pages[0].metadata['source'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNn8fnlqRvZ0",
        "outputId": "e38d4d65-adab-438e-9b05-284cedc6f036"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "<class 'langchain_core.documents.base.Document'>\n",
            "{'source': '/content/pdf.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_spliter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap = 100,\n",
        "    length_function =len\n",
        ")"
      ],
      "metadata": {
        "id": "A3cywTn8a_4u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_spliter.create_documents([text_gen_ai])"
      ],
      "metadata": {
        "id": "ujxxBkhGcq3H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VklTF0PbbbJF",
        "outputId": "43f97bff-88a0-4281-e6e8-1113d5d63d02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI can learn from existing artifacts to generate new, realistic artifacts (at scale) that reflect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = []\n",
        "for i in range(len(docs)):\n",
        "  char_list.append(len(docs[i].page_content))\n",
        "\n",
        "print(char_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVo1quDBcaOv",
        "outputId": "9e62e1a5-6624-44ee-cec3-7faee3164baf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 95, 97, 98, 99, 97, 96, 98, 99, 98, 92, 98, 99, 97, 95, 92, 97, 98, 97, 97, 99, 97, 97, 97, 96, 93, 96, 97, 98, 96, 99, 95, 96, 98, 97, 97, 96, 93, 98, 96, 97, 98, 97, 97, 99, 95, 93, 99, 99, 95, 99, 97, 93, 96, 97, 94, 99, 93, 99, 97, 97, 93, 94, 98, 93, 97, 99, 98, 96, 95, 98, 91, 96, 97, 97, 94, 97, 97, 99, 93, 50, 98, 97, 96, 99, 94, 98, 94, 90, 96, 99, 97, 95, 99, 98, 95, 97, 96, 96, 99, 98, 99, 99, 98, 96, 95, 99, 93, 98, 99, 90, 94, 93, 94, 99, 98, 94, 98, 98, 91, 98, 90, 98, 94, 95, 92, 96, 98, 96, 95, 98, 98, 95, 98, 98, 97, 97, 99, 95, 96, 99, 97, 94, 90, 96, 97, 98, 98, 96, 96, 97, 96, 72, 97, 93, 98, 98, 98, 95, 96, 99, 99, 99, 99, 94, 98, 97, 98, 94, 89, 96, 93, 95, 96, 97, 98, 97, 94, 95, 96, 99, 98, 99, 96, 98, 99, 96, 99, 99, 96, 98, 93, 98, 99, 97, 95, 98, 93, 98, 95, 97, 99, 92, 93, 96, 99, 98, 96, 93, 97, 95, 99, 98, 98, 93, 97, 99, 99, 94, 97, 98, 98, 97, 95, 99, 96, 91, 99, 94, 99, 95, 98, 98, 96, 96, 98, 97, 97, 92, 93, 97, 94, 98, 99, 96, 99, 97, 95, 96, 36, 93, 96, 97, 99, 99, 92, 99, 94, 96, 98, 98, 99, 98, 99, 99, 92, 97, 97, 97, 93, 98, 98, 97, 99, 95, 97, 94, 93, 94, 94, 99, 97, 96, 98, 99, 99, 93, 95, 96, 96, 91, 35, 92, 95, 99, 97, 99, 96, 97, 88, 97, 96, 95, 94, 94, 97, 97, 91, 93, 94, 93, 95, 90, 96, 92, 97, 99, 94, 99, 98, 97, 93, 95, 96, 92, 99, 99, 94, 96, 97, 97, 94, 96, 97, 96, 93, 97, 98, 98, 99, 99, 97, 93, 97, 99, 93, 98, 97, 91, 93, 95, 86, 94, 96, 96, 97, 95, 98, 98, 99, 95, 98, 99, 99, 99, 96, 92, 96, 97, 98, 96, 98, 97, 98, 95, 93, 96, 93, 98, 94, 99, 99, 99, 98, 87, 92, 92, 98, 94, 96, 99, 96, 98, 98, 95, 60, 94, 92, 96, 99, 98, 98, 95, 95, 98, 95, 97, 89, 97, 69, 96, 98, 94, 97, 99, 97, 97, 96, 97, 95, 96, 95, 98, 99, 99, 98, 98, 96, 94, 95, 97, 96, 96, 96, 96, 98, 89, 97, 96, 97, 97, 97, 97, 99, 97, 99, 94, 97, 98, 99, 98, 95, 97, 96, 97, 99, 98, 98, 99, 81, 92, 98, 95, 98, 97, 97, 97, 97, 99, 97, 95, 92, 99, 97, 92, 95, 91, 70, 98, 99, 96, 92, 94, 69, 92, 84, 85, 95, 92, 97, 92, 88, 82, 77, 50, 71, 95, 90, 95, 89, 86, 27, 51, 98, 97, 99, 98, 96, 99, 99, 95, 95, 93, 99, 98, 77, 95, 97, 97, 95, 98, 96, 99, 96, 91, 98, 93, 99, 98, 94, 94, 96, 97, 94, 96, 93, 96, 35, 98, 97, 91, 99, 96, 91, 92, 98, 98, 97, 94, 97, 99, 96, 99, 96, 99, 95, 97, 98, 98, 98, 92, 97, 98, 99, 96, 97, 95, 95, 92, 94, 94, 98, 99, 89, 97, 98, 97, 94, 93, 99, 94, 99, 93, 99, 95, 96, 96, 95, 97, 96, 92, 97, 95, 95, 96, 96, 95, 96, 97, 18, 96, 97, 91, 99, 95, 96, 99, 98, 96, 93, 96, 99, 98, 94, 97, 94, 96, 95, 95, 99, 93, 98, 98, 99, 95, 99, 94, 96, 70, 98, 97, 97, 97, 91, 96, 93, 98, 93, 99, 99, 95, 93, 92, 96, 99, 94, 98, 92, 96, 97, 97, 96, 89, 92, 97, 91, 97, 93, 90, 96, 94, 97, 94, 99, 97, 98, 99, 99, 97, 96, 89, 98, 97, 92, 99, 94, 98, 98, 97, 98, 94, 95, 98, 95, 96, 98, 97, 96, 92, 98, 97, 93, 99, 97, 96, 98, 97, 97, 96, 98, 97, 95, 97, 97, 98, 94, 96, 99, 99, 98, 97, 99, 97, 95, 98, 96, 98, 97, 97, 93, 97, 89, 52, 90, 91, 97, 92, 96, 96, 94, 94, 98, 99, 99, 91, 96, 93, 95, 98, 97, 98, 94, 98, 96, 91, 97, 95, 93, 98, 95, 97, 99, 99, 99, 93, 96, 99, 98, 92, 92, 95, 97, 99, 92, 99, 98, 89, 97, 99, 96, 99, 96, 98, 98, 95, 83, 97, 95, 96, 98, 98, 96, 97, 99, 99, 94, 97, 93, 99, 92, 98, 99, 96, 91, 22, 50, 99, 90, 99, 99, 94, 94, 98, 98, 99, 99, 89, 95, 97, 94, 99, 99, 97, 93, 99, 96, 95, 98, 99, 95, 97, 96, 71, 85, 98, 93, 96, 97, 93, 92, 93, 97, 94, 98, 95, 97, 97, 99, 99, 98, 98, 94, 94, 51, 98, 97, 99, 98, 99, 96, 96, 99, 97, 96, 91, 95, 98, 94, 99, 98, 97, 98, 98, 98, 95, 99, 97, 98, 98, 95, 95, 96, 98, 92, 95, 89, 95, 93, 96, 94, 98, 95, 96, 95, 99, 94, 98, 98, 97, 97, 97, 98, 98, 97, 99, 93, 98, 96, 99, 95, 97, 97, 98, 96, 97, 97, 97, 94, 98, 94, 96, 99, 97, 96, 97, 96, 98, 98, 88, 97, 96, 95, 97, 95, 94, 97, 99, 98, 99, 96, 90, 97, 99, 93, 99, 97, 97, 99, 40, 96, 92, 99, 99, 98, 98, 96, 98, 97, 99, 99, 99, 90, 96, 93, 99, 98, 92, 96, 97, 96, 98, 98, 99, 98, 93, 95, 99, 98, 94, 99, 99, 94, 99, 95, 94, 96, 98, 97, 98, 98, 96, 98, 96, 93, 91, 96, 97, 97, 99, 96, 99, 98, 94, 91, 97, 98, 92, 97, 97, 95, 95, 93, 93, 98, 99, 95, 98, 99, 95, 97, 99, 99, 97, 93, 97, 96, 98, 95, 94, 93, 94, 97, 93, 99, 99, 99, 98, 97, 89, 69, 98, 98, 99, 95, 98, 99, 92, 97, 99, 96, 97, 94, 96, 97, 99, 93, 95, 98, 97, 99, 96, 99, 97, 95, 99, 95, 93, 96, 99, 98, 97, 92, 98, 97, 97, 96, 97, 96, 97, 90, 97, 98, 97, 97, 95, 97, 98, 98, 96, 99, 97, 94, 94, 97, 99, 97, 94, 97, 97, 95, 97, 98, 99, 98, 96, 98, 99, 98, 95, 99, 96, 98, 95, 93, 97, 96, 96, 94, 94, 98, 90, 96, 96, 97, 99, 96, 98, 97, 93, 99, 98, 96, 96, 95, 99, 96, 96, 97, 96, 95, 98, 99, 98, 95, 96, 97, 98, 98, 99, 95, 97, 93, 95, 98, 91, 94, 94, 97, 98, 92, 62, 95, 99, 95, 98, 97, 98, 98, 91, 99, 98, 97, 97, 91, 98, 93, 90, 98, 97, 97, 98, 98, 95, 97, 37, 61, 98, 97, 96, 98, 98, 95, 96, 96, 98, 96, 98, 95, 96, 97, 99, 96, 96, 96, 97, 98, 99, 96, 96, 91, 90, 98, 98, 96, 96, 96, 98, 98, 96, 97, 95, 98, 99, 99, 98, 97, 98, 97, 99, 99, 99, 92, 97, 93, 96, 96, 61, 98, 94, 94, 91, 97, 94, 99, 98, 95, 99, 99, 97, 98, 94, 97, 98, 96, 98, 98, 97, 98, 91, 99, 94, 93, 97, 99, 92, 96, 99, 96, 99, 99, 97, 96, 93, 99, 94, 99, 97, 96, 97, 96, 93, 96, 97, 97, 97, 98, 96, 96, 98, 99, 97, 95, 99, 98, 95, 95, 96, 94, 98, 98, 99, 95, 99, 88, 95, 98, 99, 99, 96, 99, 98, 96, 96, 95, 96, 96, 96, 94, 98, 96, 97, 95, 97, 91, 93, 96, 97, 99, 95, 97, 99, 99, 94, 94, 98, 99, 96, 99, 99, 96, 96, 94, 96, 99, 96, 94, 97, 95, 94, 95, 94]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토큰 단위 텍스트 분할기"
      ],
      "metadata": {
        "id": "yd21OAUvdXBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqNFllZ9c3VD",
        "outputId": "bd7b449e-b511-4be6-bca8-4f95aa911421"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "#토큰 수를 세는 함수\n",
        "def tiktoken_len(text):\n",
        "  tokens = tokenizer.encode(text)\n",
        "  return len(tokens)"
      ],
      "metadata": {
        "id": "Ch-p6lDSd-pS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs[0].page_content))\n",
        "print(str(tiktoken_len(docs[0].page_content)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChPLYYrVeYGp",
        "outputId": "c7c89287-fa7e-487d-91e7-76ff3be69072"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_spliter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50,\n",
        "    length_function = tiktoken_len\n",
        ")\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "jHyHilLmggy6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtBqg_xhC7g",
        "outputId": "326e898c-15b7-4f1b-fa21-ce3e47b10100"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = []\n",
        "for i in range(len(docs)):\n",
        "  token_list.append(tiktoken_len(docs[i].page_content))\n",
        "\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN8hbqX5h7pU",
        "outputId": "2b85b4fa-bc27-4813-b4dd-17ec56f7d39b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[168, 244, 1237, 1167, 1206, 1214, 1348, 1162, 1015, 864, 981, 809, 774, 928, 886, 829, 740, 332, 67]\n"
          ]
        }
      ]
    }
  ]
}